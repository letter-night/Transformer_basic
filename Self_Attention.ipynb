{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Self Attention in Transformers"
      ],
      "metadata": {
        "id": "gO5Z0qErNuOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Data"
      ],
      "metadata": {
        "id": "HedntyUvLrBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "L, d_k, d_v = 4, 8, 8\n",
        "q = np.random.randn(L, d_k)\n",
        "k = np.random.randn(L, d_k)\n",
        "v = np.random.randn(L, d_v)\n",
        "\n",
        "print(\"Q\\n\", q)\n",
        "print(\"K\\n\", k)\n",
        "print(\"V\\n\", v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7aVkkUsEeEN",
        "outputId": "5702674e-b6f6-4931-b0fc-aaba261c51bf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " [[ 0.84510417  1.30397454  0.45100508 -0.67824654  2.3060361  -1.73760495\n",
            "   1.1420773   2.25201506]\n",
            " [-0.9376166  -0.81154269  0.63237914  0.55951021  0.92674594 -1.39842678\n",
            "  -0.14587156 -0.53715604]\n",
            " [ 0.23079479  1.69128727 -1.51817407  0.3747922  -1.90436554  1.05433816\n",
            "  -0.44561986  0.91408995]\n",
            " [ 0.24704611 -0.86427673 -0.14569616 -0.91861466  1.37835583 -1.71164589\n",
            "  -2.33833465 -0.13990678]]\n",
            "K\n",
            " [[ 0.26287575  2.63274413  1.54619777 -0.53768774  0.00913412  0.14395188\n",
            "  -1.19963181 -0.6381176 ]\n",
            " [ 2.69091111  0.46237734  0.26917815 -0.59716749 -0.51476364  0.23443706\n",
            "  -0.04547368  0.14264032]\n",
            " [ 0.89627259  0.38445796 -1.99429564 -1.9715818   2.10926488  0.66549909\n",
            "   2.19478266  1.36357753]\n",
            " [ 0.65696906  0.51045855  0.82746194 -0.1419481   0.4985914  -1.13144129\n",
            "  -1.16321744  0.42983977]]\n",
            "V\n",
            " [[ 0.6588293   1.1037471  -0.01056483 -0.66015284  0.79941062 -0.63669914\n",
            "  -0.70311896 -0.46655459]\n",
            " [-0.48387534 -0.10511596 -0.13599462  0.278638   -0.9677274  -0.77453905\n",
            "   0.00375995  0.16098828]\n",
            " [-1.40290072  0.1186923  -0.5685867   0.36663395 -0.85246773 -0.45377942\n",
            "   0.62711322 -0.97631125]\n",
            " [ 1.30328186  0.41514855  1.41360249  1.41993605 -1.27116376  0.45214769\n",
            "  -2.90182862 -0.16488692]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self Attention\n",
        "\n",
        "$$\n",
        "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{new V} = \\text{self attention}.V\n",
        "$$"
      ],
      "metadata": {
        "id": "tV6txskBLwjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(q, k.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIPhYyEeGwld",
        "outputId": "62e260e5-2f35-4140-dac7-8dfb2f01f92a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.68102601,  2.07832712, 10.98162318,  4.44558675],\n",
              "       [-1.38119977, -3.9370655 , -3.54514458,  1.39669891],\n",
              "       [ 2.05014059,  2.14871229,  0.09908186, -1.52563221],\n",
              "       [ 0.71878874, -0.24991861, -1.56386356,  5.0146791 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Why we need sqrt(d_k) in denominator\n",
        "q.var(), k.var(), np.matmul(q, k.T).var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nTTQm8CG31Z",
        "outputId": "7bf1f722-2202-4508-9a7a-ba66b2ca5415"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4464753310180924, 1.3153693878270274, 12.348347458496317)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
        "q.var(), k.var(), scaled.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNMnoLSyG89J",
        "outputId": "306a5d10-9810-4c55-ddd7-66580e4311ff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.4464753310180924, 1.3153693878270274, 1.5435434323120394)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the reduction in variance of the product"
      ],
      "metadata": {
        "id": "ypO9IK1PL3cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wsMdBlIHLaa",
        "outputId": "624a6dbd-f2f8-491f-d151-7042bc7adc50"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.59433245,  0.7347996 ,  3.88259011,  1.57175227],\n",
              "       [-0.48832786, -1.39196286, -1.25339789,  0.49380763],\n",
              "       [ 0.72483416,  0.75968452,  0.03503073, -0.53939244],\n",
              "       [ 0.2541302 , -0.08835957, -0.55290926,  1.7729568 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masking\n",
        "\n",
        "- This is to ensure words don't get context from words generated in the future.\n",
        "- Not required in the encoders, but required int he decoders"
      ],
      "metadata": {
        "id": "Dmz4v-RmMAaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.tril(np.ones( (L, L) ))\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wapPTnrAHPtU",
        "outputId": "ab30dc99-d565-471c-90e4-bfb4d493513d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [1., 1., 0., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[mask == 0] = -np.infty\n",
        "mask[mask == 1] = 0\n",
        "\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGs8FjBMHXpq",
        "outputId": "ce0cb6f3-d81f-4754-bab0-3e6509602aa4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0., -inf, -inf, -inf],\n",
              "       [  0.,   0., -inf, -inf],\n",
              "       [  0.,   0.,   0., -inf],\n",
              "       [  0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled + mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yc4NKuKHeoj",
        "outputId": "bc28605d-7d70-4565-d279-bec60b45326c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.59433245,        -inf,        -inf,        -inf],\n",
              "       [-0.48832786, -1.39196286,        -inf,        -inf],\n",
              "       [ 0.72483416,  0.75968452,  0.03503073,        -inf],\n",
              "       [ 0.2541302 , -0.08835957, -0.55290926,  1.7729568 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax\n",
        "\n",
        "$$\n",
        "\\text{softmax} = \\frac{e^{x_i}}{\\sum_j e^x_j}\n",
        "$$"
      ],
      "metadata": {
        "id": "XMTAXjooN9eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
      ],
      "metadata": {
        "id": "FHsxMAEKHgNL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = softmax(scaled + mask)\n",
        "\n",
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuou9N3wHmyK",
        "outputId": "ae784b50-2bbb-4eff-a591-3bc625f27cca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        , 0.        ],\n",
              "       [0.71169592, 0.28830408, 0.        , 0.        ],\n",
              "       [0.39414468, 0.40812292, 0.1977324 , 0.        ],\n",
              "       [0.14874222, 0.10560703, 0.06636536, 0.67928538]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_v = np.matmul(attention, v)\n",
        "new_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kSgwPJwHoz6",
        "outputId": "3f8d9c9d-382d-4125-a4e2-916bb0cbd175"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6588293 ,  1.1037471 , -0.01056483, -0.66015284,  0.79941062,\n",
              "        -0.63669914, -0.70311896, -0.46655459],\n",
              "       [ 0.3293829 ,  0.75522695, -0.04672675, -0.38949561,  0.28993753,\n",
              "        -0.67643895, -0.49932289, -0.28563142],\n",
              "       [-0.21520548,  0.41560512, -0.17209461, -0.07398176, -0.24842878,\n",
              "        -0.65678561, -0.15159547, -0.31123537],\n",
              "       [ 0.8390914 ,  0.44295421,  0.90657162,  0.92010714, -0.90335   ,\n",
              "         0.10052127, -2.03373757, -0.2291934 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdB68-tEIKw-",
        "outputId": "18142508-9e8a-4a23-94f6-a475c5a90096"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6588293 ,  1.1037471 , -0.01056483, -0.66015284,  0.79941062,\n",
              "        -0.63669914, -0.70311896, -0.46655459],\n",
              "       [-0.48387534, -0.10511596, -0.13599462,  0.278638  , -0.9677274 ,\n",
              "        -0.77453905,  0.00375995,  0.16098828],\n",
              "       [-1.40290072,  0.1186923 , -0.5685867 ,  0.36663395, -0.85246773,\n",
              "        -0.45377942,  0.62711322, -0.97631125],\n",
              "       [ 1.30328186,  0.41514855,  1.41360249,  1.41993605, -1.27116376,\n",
              "         0.45214769, -2.90182862, -0.16488692]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function"
      ],
      "metadata": {
        "id": "nSiJuBQELFHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "    d_k = q.shape[-1]\n",
        "    scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scaled = scaled + mask\n",
        "        attention = softmax(scaled)\n",
        "        out = np.matmul(attention, v)\n",
        "        return out, attention"
      ],
      "metadata": {
        "id": "zrMjgZd5IMFJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
        "print(\"Q\\n\", q)\n",
        "print(\"K\\n\", k)\n",
        "print(\"V\\n\", v)\n",
        "print(\"New V\\n\", values)\n",
        "print(\"Attention\\n\", attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmfh0b6JIgWb",
        "outputId": "9512fc4e-d3c0-4e26-f216-fd790a638440"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q\n",
            " [[ 0.84510417  1.30397454  0.45100508 -0.67824654  2.3060361  -1.73760495\n",
            "   1.1420773   2.25201506]\n",
            " [-0.9376166  -0.81154269  0.63237914  0.55951021  0.92674594 -1.39842678\n",
            "  -0.14587156 -0.53715604]\n",
            " [ 0.23079479  1.69128727 -1.51817407  0.3747922  -1.90436554  1.05433816\n",
            "  -0.44561986  0.91408995]\n",
            " [ 0.24704611 -0.86427673 -0.14569616 -0.91861466  1.37835583 -1.71164589\n",
            "  -2.33833465 -0.13990678]]\n",
            "K\n",
            " [[ 0.26287575  2.63274413  1.54619777 -0.53768774  0.00913412  0.14395188\n",
            "  -1.19963181 -0.6381176 ]\n",
            " [ 2.69091111  0.46237734  0.26917815 -0.59716749 -0.51476364  0.23443706\n",
            "  -0.04547368  0.14264032]\n",
            " [ 0.89627259  0.38445796 -1.99429564 -1.9715818   2.10926488  0.66549909\n",
            "   2.19478266  1.36357753]\n",
            " [ 0.65696906  0.51045855  0.82746194 -0.1419481   0.4985914  -1.13144129\n",
            "  -1.16321744  0.42983977]]\n",
            "V\n",
            " [[ 0.6588293   1.1037471  -0.01056483 -0.66015284  0.79941062 -0.63669914\n",
            "  -0.70311896 -0.46655459]\n",
            " [-0.48387534 -0.10511596 -0.13599462  0.278638   -0.9677274  -0.77453905\n",
            "   0.00375995  0.16098828]\n",
            " [-1.40290072  0.1186923  -0.5685867   0.36663395 -0.85246773 -0.45377942\n",
            "   0.62711322 -0.97631125]\n",
            " [ 1.30328186  0.41514855  1.41360249  1.41993605 -1.27116376  0.45214769\n",
            "  -2.90182862 -0.16488692]]\n",
            "New V\n",
            " [[ 0.6588293   1.1037471  -0.01056483 -0.66015284  0.79941062 -0.63669914\n",
            "  -0.70311896 -0.46655459]\n",
            " [ 0.3293829   0.75522695 -0.04672675 -0.38949561  0.28993753 -0.67643895\n",
            "  -0.49932289 -0.28563142]\n",
            " [-0.21520548  0.41560512 -0.17209461 -0.07398176 -0.24842878 -0.65678561\n",
            "  -0.15159547 -0.31123537]\n",
            " [ 0.8390914   0.44295421  0.90657162  0.92010714 -0.90335     0.10052127\n",
            "  -2.03373757 -0.2291934 ]]\n",
            "Attention\n",
            " [[1.         0.         0.         0.        ]\n",
            " [0.71169592 0.28830408 0.         0.        ]\n",
            " [0.39414468 0.40812292 0.1977324  0.        ]\n",
            " [0.14874222 0.10560703 0.06636536 0.67928538]]\n"
          ]
        }
      ]
    }
  ]
}